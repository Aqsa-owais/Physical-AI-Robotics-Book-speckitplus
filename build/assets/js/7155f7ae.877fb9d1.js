"use strict";(globalThis.webpackChunkphysical_ai_robotics_book=globalThis.webpackChunkphysical_ai_robotics_book||[]).push([[746],{3329:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"module-3-ai-brain/sim-to-real","title":"Sim-to-Real Transfer Concepts","description":"Introduction","source":"@site/docs/module-3-ai-brain/sim-to-real.md","sourceDirName":"module-3-ai-brain","slug":"/module-3-ai-brain/sim-to-real","permalink":"/giaic-hackathon-speckit-plus/docs/module-3-ai-brain/sim-to-real","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-brain/sim-to-real.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10},"sidebar":"tutorialSidebar","previous":{"title":"Navigation and Path Planning using Nav2","permalink":"/giaic-hackathon-speckit-plus/docs/module-3-ai-brain/navigation"},"next":{"title":"Infrastructure: Hardware, Simulation Rigs, and Deployment Models","permalink":"/giaic-hackathon-speckit-plus/docs/infrastructure/"}}');var i=a(4848),t=a(8453);const r={sidebar_position:10},o="Sim-to-Real Transfer Concepts",l={},d=[{value:"Introduction",id:"introduction",level:2},{value:"The Reality Gap",id:"the-reality-gap",level:2},{value:"Definition",id:"definition",level:3},{value:"Types of Reality Gaps",id:"types-of-reality-gaps",level:3},{value:"1. Visual Reality Gap",id:"1-visual-reality-gap",level:4},{value:"2. Physical Reality Gap",id:"2-physical-reality-gap",level:4},{value:"3. Temporal Reality Gap",id:"3-temporal-reality-gap",level:4},{value:"Sim-to-Real Transfer Techniques",id:"sim-to-real-transfer-techniques",level:2},{value:"1. Domain Randomization",id:"1-domain-randomization",level:3},{value:"2. System Identification",id:"2-system-identification",level:3},{value:"3. Domain Adaptation",id:"3-domain-adaptation",level:3},{value:"Transfer Learning Approaches",id:"transfer-learning-approaches",level:2},{value:"1. Pre-training in Simulation",id:"1-pre-training-in-simulation",level:3},{value:"2. Few-Shot Adaptation",id:"2-few-shot-adaptation",level:3},{value:"Practical Transfer Strategies",id:"practical-transfer-strategies",level:2},{value:"1. Progressive Domain Randomization",id:"1-progressive-domain-randomization",level:3},{value:"2. Reality Check and Validation",id:"2-reality-check-and-validation",level:3},{value:"Isaac ROS Specific Transfer Considerations",id:"isaac-ros-specific-transfer-considerations",level:2},{value:"1. Isaac ROS Perception Transfer",id:"1-isaac-ros-perception-transfer",level:3},{value:"2. Isaac ROS Control Transfer",id:"2-isaac-ros-control-transfer",level:3},{value:"Best Practices for Successful Transfer",id:"best-practices-for-successful-transfer",level:2},{value:"1. Validation Strategy",id:"1-validation-strategy",level:3},{value:"2. Gradual Deployment",id:"2-gradual-deployment",level:3},{value:"Troubleshooting Transfer Issues",id:"troubleshooting-transfer-issues",level:2},{value:"1. Common Transfer Problems",id:"1-common-transfer-problems",level:3},{value:"2. Debugging Transfer Issues",id:"2-debugging-transfer-issues",level:3},{value:"Summary",id:"summary",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"sim-to-real-transfer-concepts",children:"Sim-to-Real Transfer Concepts"})}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(n.p,{children:'Sim-to-Real transfer is the process of taking capabilities learned in simulation and successfully deploying them on real robots. This is a fundamental challenge in robotics, as perfect simulation is impossible due to the "reality gap" between simulated and real environments. This guide covers the key concepts, techniques, and best practices for achieving successful sim-to-real transfer.'}),"\n",(0,i.jsx)(n.h2,{id:"the-reality-gap",children:"The Reality Gap"}),"\n",(0,i.jsx)(n.h3,{id:"definition",children:"Definition"}),"\n",(0,i.jsx)(n.p,{children:"The reality gap refers to the differences between simulated and real-world environments that can cause behaviors learned in simulation to fail when deployed on real robots. These differences include:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dynamics"}),": Friction, compliance, and mechanical properties"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensing"}),": Noise, resolution, and sensor characteristics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actuation"}),": Motor responses, delays, and power limitations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Environment"}),": Lighting, surfaces, and external disturbances"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"System Latencies"}),": Processing delays and communication latencies"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"types-of-reality-gaps",children:"Types of Reality Gaps"}),"\n",(0,i.jsx)(n.h4,{id:"1-visual-reality-gap",children:"1. Visual Reality Gap"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Causes"}),": Different lighting, textures, and rendering quality"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Effects"}),": Vision-based perception and navigation failures"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mitigation"}),": Domain randomization, photo-realistic rendering"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"2-physical-reality-gap",children:"2. Physical Reality Gap"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Causes"}),": Different friction coefficients, masses, and inertias"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Effects"}),": Motion planning and control failures"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mitigation"}),": Accurate physics simulation, system identification"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"3-temporal-reality-gap",children:"3. Temporal Reality Gap"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Causes"}),": Different processing speeds and communication delays"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Effects"}),": Timing-dependent behaviors failure"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mitigation"}),": Latency modeling, real-time constraints"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"sim-to-real-transfer-techniques",children:"Sim-to-Real Transfer Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"1-domain-randomization",children:"1. Domain Randomization"}),"\n",(0,i.jsx)(n.p,{children:"Domain randomization is a technique that increases the diversity of training environments to improve robustness:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport random\n\nclass DomainRandomizer:\n    def __init__(self):\n        self.randomization_ranges = {\n            'lighting_intensity': (0.5, 2.0),\n            'object_colors': (0.0, 1.0),  # RGB values\n            'friction_coeff': (0.1, 1.0),\n            'mass_variance': (0.8, 1.2),\n            'texture_scale': (0.5, 2.0),\n            'camera_noise': (0.0, 0.05),\n            'actuator_delay': (0.0, 0.1)\n        }\n\n    def randomize_environment(self, episode_number):\n        \"\"\"Randomize environment parameters\"\"\"\n        randomization_params = {}\n\n        for param, (min_val, max_val) in self.randomization_ranges.items():\n            # Progressive randomization - start conservative, increase over time\n            progress = min(episode_number / 1000.0, 1.0)  # Scale from 0 to 1\n            range_size = (max_val - min_val) * progress\n            center = (max_val + min_val) / 2.0\n            current_min = center - range_size / 2.0\n            current_max = center + range_size / 2.0\n\n            randomization_params[param] = np.random.uniform(current_min, current_max)\n\n        return randomization_params\n\n    def apply_randomization(self, sim_env, params):\n        \"\"\"Apply randomization parameters to simulation environment\"\"\"\n        # Randomize lighting\n        sim_env.set_lighting_intensity(params['lighting_intensity'])\n\n        # Randomize object properties\n        for obj in sim_env.get_objects():\n            # Randomize color\n            color = (random.random(), random.random(), random.random())\n            obj.set_color(color)\n\n            # Randomize friction\n            obj.set_friction(params['friction_coeff'])\n\n            # Randomize mass\n            base_mass = obj.get_base_mass()\n            randomized_mass = base_mass * params['mass_variance']\n            obj.set_mass(randomized_mass)\n\n        # Randomize sensor noise\n        sim_env.set_camera_noise_std(params['camera_noise'])\n        sim_env.set_actuator_delay(params['actuator_delay'])\n\n        return sim_env\n"})}),"\n",(0,i.jsx)(n.h3,{id:"2-system-identification",children:"2. System Identification"}),"\n",(0,i.jsx)(n.p,{children:"System identification involves measuring real robot characteristics to improve simulation accuracy:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import numpy as np\nfrom scipy.optimize import minimize\nfrom collections import deque\n\nclass SystemIdentifier:\n    def __init__(self):\n        self.measurement_buffer = deque(maxlen=1000)\n        self.simulation_parameters = {\n            'motor_time_constant': 0.1,\n            'gear_ratio': 1.0,\n            'encoder_resolution': 1000,\n            'friction_viscous': 0.01,\n            'friction_coulomb': 0.1,\n            'mass': 1.0,\n            'inertia': 0.1\n        }\n\n    def collect_data(self, real_robot, sim_robot, inputs):\n        \"\"\"Collect input-output data from real and simulated robots\"\"\"\n        real_outputs = []\n        sim_outputs = []\n\n        for input_cmd in inputs:\n            # Apply input to both robots\n            real_output = real_robot.apply_input(input_cmd)\n            sim_output = sim_robot.apply_input(input_cmd)\n\n            self.measurement_buffer.append({\n                'input': input_cmd,\n                'real_output': real_output,\n                'sim_output': sim_output\n            })\n\n            real_outputs.append(real_output)\n            sim_outputs.append(sim_output)\n\n        return real_outputs, sim_outputs\n\n    def identify_parameters(self):\n        \"\"\"Identify system parameters by minimizing simulation error\"\"\"\n        def objective_function(params):\n            # Update simulation with candidate parameters\n            self.update_simulation_params(params)\n\n            # Calculate error between real and simulated outputs\n            total_error = 0.0\n            for measurement in self.measurement_buffer:\n                sim_output = self.sim_robot.apply_input(measurement['input'])\n                error = np.linalg.norm(\n                    np.array(measurement['real_output']) - np.array(sim_output)\n                )\n                total_error += error\n\n            return total_error\n\n        # Initial guess based on nominal values\n        initial_params = self.get_current_params()\n\n        # Optimize parameters\n        result = minimize(objective_function, initial_params, method='BFGS')\n\n        # Update with optimized parameters\n        self.update_simulation_params(result.x)\n\n        return result.x\n\n    def get_current_params(self):\n        \"\"\"Get current parameter values as array\"\"\"\n        return np.array(list(self.simulation_parameters.values()))\n\n    def update_simulation_params(self, params):\n        \"\"\"Update simulation parameters from array\"\"\"\n        param_keys = list(self.simulation_parameters.keys())\n        for i, key in enumerate(param_keys):\n            if i < len(params):\n                self.simulation_parameters[key] = params[i]\n\n        # Apply parameters to simulation\n        self.apply_to_simulation()\n\n    def apply_to_simulation(self):\n        \"\"\"Apply parameters to simulation environment\"\"\"\n        # Update robot dynamics\n        self.sim_robot.set_motor_time_constant(\n            self.simulation_parameters['motor_time_constant']\n        )\n        self.sim_robot.set_friction(\n            viscous=self.simulation_parameters['friction_viscous'],\n            coulomb=self.simulation_parameters['friction_coulomb']\n        )\n        self.sim_robot.set_mass(self.simulation_parameters['mass'])\n        self.sim_robot.set_inertia(self.simulation_parameters['inertia'])\n"})}),"\n",(0,i.jsx)(n.h3,{id:"3-domain-adaptation",children:"3. Domain Adaptation"}),"\n",(0,i.jsx)(n.p,{children:"Domain adaptation techniques help models adapt to new domains:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DomainAdaptationNetwork(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256):\n        super(DomainAdaptationNetwork, self).__init__()\n\n        # Feature extractor (shared between domains)\n        self.feature_extractor = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim)\n        )\n\n        # Task-specific classifier\n        self.task_classifier = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)  # Example: binary classification\n        )\n\n        # Domain classifier\n        self.domain_classifier = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x, domain_label=None):\n        features = self.feature_extractor(x)\n\n        task_output = self.task_classifier(features)\n\n        if domain_label is not None:\n            # During training, also return domain classification\n            domain_output = self.domain_classifier(features)\n            return task_output, domain_output\n        else:\n            # During inference, only return task output\n            return task_output\n\nclass DomainAdversarialTrainer:\n    def __init__(self, model):\n        self.model = model\n        self.task_criterion = nn.MSELoss()\n        self.domain_criterion = nn.BCELoss()\n        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    def train_step(self, sim_data, real_data):\n        """Single training step with domain adversarial loss"""\n        # Label domain data (0 for sim, 1 for real)\n        sim_domain_labels = torch.zeros(sim_data.size(0), 1)\n        real_domain_labels = torch.ones(real_data.size(0), 1)\n\n        # Combine data\n        combined_data = torch.cat([sim_data, real_data], dim=0)\n        combined_domains = torch.cat([sim_domain_labels, real_domain_labels], dim=0)\n\n        # Forward pass\n        task_pred, domain_pred = self.model(combined_data, domain_label=True)\n\n        # Split predictions\n        sim_task_pred = task_pred[:sim_data.size(0)]\n        real_task_pred = task_pred[sim_data.size(0):]\n\n        sim_domain_pred = domain_pred[:sim_data.size(0)]\n        real_domain_pred = domain_pred[sim_data.size(0):]\n\n        # Calculate losses\n        # Task loss (only for real data if real labels available)\n        real_task_loss = self.task_criterion(real_task_pred, real_targets)  # Need real targets\n\n        # Domain confusion loss (make domains indistinguishable)\n        sim_domain_loss = self.domain_criterion(sim_domain_pred, torch.zeros_like(sim_domain_labels))\n        real_domain_loss = self.domain_criterion(real_domain_pred, torch.ones_like(real_domain_labels))\n        domain_loss = sim_domain_loss + real_domain_loss\n\n        # Total loss (negative domain loss to confuse discriminator)\n        total_loss = real_task_loss - 0.1 * domain_loss\n\n        # Backpropagate\n        self.optimizer.zero_grad()\n        total_loss.backward()\n        self.optimizer.step()\n\n        return total_loss.item()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"transfer-learning-approaches",children:"Transfer Learning Approaches"}),"\n",(0,i.jsx)(n.h3,{id:"1-pre-training-in-simulation",children:"1. Pre-training in Simulation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class SimToRealTransferLearner:\n    def __init__(self, policy_network):\n        self.sim_policy = policy_network  # Policy trained in simulation\n        self.real_policy = None  # Will be adapted for real robot\n        self.transfer_learning_rate = 0.001\n\n    def pretrain_in_simulation(self, sim_env, episodes=10000):\n        """Pre-train policy in simulation"""\n        optimizer = torch.optim.Adam(self.sim_policy.parameters())\n\n        for episode in range(episodes):\n            state = sim_env.reset()\n            total_reward = 0\n\n            for step in range(1000):  # Max steps per episode\n                # Get action from policy\n                action = self.sim_policy(torch.FloatTensor(state))\n\n                # Take action in simulation\n                next_state, reward, done, info = sim_env.step(action.detach().numpy())\n\n                # Train on simulation data\n                loss = self.compute_loss(state, action, reward, next_state)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n                state = next_state\n                total_reward += reward\n\n                if done:\n                    break\n\n            if episode % 100 == 0:\n                print(f"Sim Episode {episode}, Reward: {total_reward}")\n\n    def adapt_to_real_robot(self, real_env, adaptation_episodes=1000):\n        """Adapt pre-trained simulation policy to real robot"""\n        # Initialize real robot policy with simulation weights\n        self.real_policy = self.copy_policy_weights(self.sim_policy)\n\n        optimizer = torch.optim.Adam(self.real_policy.parameters(),\n                                   lr=self.transfer_learning_rate)\n\n        for episode in range(adaptation_episodes):\n            state = real_env.reset()\n            total_reward = 0\n\n            for step in range(1000):\n                # Get action from adapted policy\n                action = self.real_policy(torch.FloatTensor(state))\n\n                # Take action on real robot\n                next_state, reward, done, info = real_env.step(action.detach().numpy())\n\n                # Train on real robot data (fine-tuning)\n                loss = self.compute_loss(state, action, reward, next_state)\n\n                # Add regularization to preserve simulation knowledge\n                sim_regularization = self.preserve_sim_knowledge()\n                total_loss = loss + 0.1 * sim_regularization\n\n                optimizer.zero_grad()\n                total_loss.backward()\n                optimizer.step()\n\n                state = next_state\n                total_reward += reward\n\n                if done:\n                    break\n\n            if episode % 100 == 0:\n                print(f"Real Episode {episode}, Reward: {total_reward}")\n\n    def preserve_sim_knowledge(self):\n        """Regularization term to preserve simulation knowledge"""\n        sim_weights = dict(self.sim_policy.named_parameters())\n        real_weights = dict(self.real_policy.named_parameters())\n\n        reg_loss = 0\n        for name, sim_param in sim_weights.items():\n            if name in real_weights:\n                reg_loss += torch.norm(sim_param - real_weights[name])\n\n        return reg_loss\n\n    def copy_policy_weights(self, source_policy):\n        """Copy policy weights to new network"""\n        target_policy = type(source_policy)()\n        target_policy.load_state_dict(source_policy.state_dict())\n        return target_policy\n'})}),"\n",(0,i.jsx)(n.h3,{id:"2-few-shot-adaptation",children:"2. Few-Shot Adaptation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class FewShotAdapter:\n    def __init__(self, base_policy):\n        self.base_policy = base_policy\n        self.adaptation_module = nn.Sequential(\n            nn.Linear(64, 32),  # Assuming 64-dim features from base policy\n            nn.ReLU(),\n            nn.Linear(32, 32),\n            nn.ReLU(),\n            nn.Linear(32, 1)  # Adaptation for specific task/robot\n        )\n\n    def adapt_with_few_samples(self, real_samples, num_updates=5):\n        """Adapt quickly with few real samples"""\n        optimizer = torch.optim.Adam(self.adaptation_module.parameters(), lr=0.01)\n\n        for update in range(num_updates):\n            total_loss = 0\n\n            for state, action, reward, next_state in real_samples:\n                # Get features from base policy\n                base_features = self.base_policy.extract_features(torch.FloatTensor(state))\n\n                # Apply adaptation\n                adapted_action = self.adaptation_module(base_features)\n\n                # Compute loss\n                target_action = torch.FloatTensor(action)\n                loss = F.mse_loss(adapted_action, target_action)\n\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n                total_loss += loss.item()\n\n            print(f"Adaptation update {update}, avg loss: {total_loss/len(real_samples)}")\n\n    def get_adapted_policy(self):\n        """Return the adapted policy"""\n        def adapted_policy(state):\n            base_features = self.base_policy.extract_features(torch.FloatTensor(state))\n            adaptation = self.adaptation_module(base_features)\n            base_action = self.base_policy(state)\n            return base_action + adaptation\n\n        return adapted_policy\n'})}),"\n",(0,i.jsx)(n.h2,{id:"practical-transfer-strategies",children:"Practical Transfer Strategies"}),"\n",(0,i.jsx)(n.h3,{id:"1-progressive-domain-randomization",children:"1. Progressive Domain Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class ProgressiveRandomizer:\n    def __init__(self):\n        self.current_episode = 0\n        self.max_episodes = 50000\n\n    def get_randomization_level(self):\n        \"\"\"Get current level of randomization based on training progress\"\"\"\n        progress = self.current_episode / self.max_episodes\n        return min(progress * 3, 3)  # Scale from 0 to 3 levels\n\n    def get_randomization_params(self):\n        \"\"\"Get randomization parameters based on current level\"\"\"\n        level = self.get_randomization_level()\n\n        if level < 1:\n            # Level 0-1: Minimal randomization (close to reality)\n            return {\n                'lighting_variation': 0.1,\n                'color_variation': 0.05,\n                'friction_range': (0.8, 1.2),\n                'mass_range': (0.9, 1.1)\n            }\n        elif level < 2:\n            # Level 1-2: Moderate randomization\n            return {\n                'lighting_variation': 0.5,\n                'color_variation': 0.3,\n                'friction_range': (0.5, 1.5),\n                'mass_range': (0.8, 1.2)\n            }\n        else:\n            # Level 2-3: Maximum randomization\n            return {\n                'lighting_variation': 1.0,\n                'color_variation': 0.8,\n                'friction_range': (0.1, 2.0),\n                'mass_range': (0.5, 1.5)\n            }\n\n    def update_randomization(self, success_rate):\n        \"\"\"Update randomization based on success rate\"\"\"\n        if success_rate > 0.8:\n            # If performing well, increase randomization\n            self.current_episode += 100\n        elif success_rate < 0.5:\n            # If performing poorly, decrease randomization\n            self.current_episode = max(0, self.current_episode - 100)\n        else:\n            # Moderate improvement, normal progression\n            self.current_episode += 10\n"})}),"\n",(0,i.jsx)(n.h3,{id:"2-reality-check-and-validation",children:"2. Reality Check and Validation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class RealityChecker:\n    def __init__(self):\n        self.sim_performance = 0.0\n        self.real_performance = 0.0\n        self.performance_history = []\n\n    def validate_transfer(self, sim_agent, real_agent, test_scenarios):\n        \"\"\"Validate transfer by comparing sim and real performance\"\"\"\n        sim_scores = []\n        real_scores = []\n\n        for scenario in test_scenarios:\n            # Test in simulation\n            sim_score = self.evaluate_agent(sim_agent, scenario, 'sim')\n            sim_scores.append(sim_score)\n\n            # Test on real robot\n            real_score = self.evaluate_agent(real_agent, scenario, 'real')\n            real_scores.append(real_score)\n\n        self.sim_performance = np.mean(sim_scores)\n        self.real_performance = np.mean(real_scores)\n\n        # Calculate sim-to-real gap\n        gap = self.sim_performance - self.real_performance\n\n        self.performance_history.append({\n            'sim_score': self.sim_performance,\n            'real_score': self.real_performance,\n            'gap': gap,\n            'date': datetime.now()\n        })\n\n        return gap\n\n    def evaluate_agent(self, agent, scenario, environment_type):\n        \"\"\"Evaluate agent in given scenario\"\"\"\n        if environment_type == 'sim':\n            env = self.get_simulation_env(scenario)\n        else:\n            env = self.get_real_env(scenario)\n\n        total_reward = 0\n        episodes = 10\n\n        for ep in range(episodes):\n            state = env.reset()\n            episode_reward = 0\n\n            for step in range(1000):\n                action = agent.act(state)\n                state, reward, done, info = env.step(action)\n                episode_reward += reward\n\n                if done:\n                    break\n\n            total_reward += episode_reward\n\n        return total_reward / episodes\n\n    def get_transfer_success_metrics(self):\n        \"\"\"Get metrics for transfer success\"\"\"\n        if not self.performance_history:\n            return None\n\n        latest = self.performance_history[-1]\n        gap_ratio = latest['gap'] / max(latest['sim_score'], 0.001)\n\n        metrics = {\n            'sim_score': latest['sim_score'],\n            'real_score': latest['real_score'],\n            'performance_gap': latest['gap'],\n            'gap_ratio': gap_ratio,\n            'transfer_efficiency': latest['real_score'] / latest['sim_score'] if latest['sim_score'] > 0 else 0\n        }\n\n        return metrics\n"})}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-specific-transfer-considerations",children:"Isaac ROS Specific Transfer Considerations"}),"\n",(0,i.jsx)(n.h3,{id:"1-isaac-ros-perception-transfer",children:"1. Isaac ROS Perception Transfer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class IsaacROSPerceptionTransfer:\n    def __init__(self):\n        self.sim_to_real_mappings = {\n            'camera_intrinsics': self.adjust_camera_intrinsics,\n            'sensor_noise': self.model_sensor_noise,\n            'processing_latency': self.account_for_latency,\n            'gpu_performance': self.adjust_for_gpu_differences\n        }\n\n    def adjust_camera_intrinsics(self, sim_camera_params, real_camera_params):\n        \"\"\"Adjust camera parameters for sim-to-real transfer\"\"\"\n        # Account for slight calibration differences\n        adjusted_params = {}\n\n        # Adjust focal length slightly\n        adjusted_params['fx'] = sim_camera_params['fx'] * 0.99  # Small adjustment\n        adjusted_params['fy'] = sim_camera_params['fy'] * 0.99\n\n        # Adjust principal point\n        adjusted_params['cx'] = sim_camera_params['cx'] + 1.0\n        adjusted_params['cy'] = sim_camera_params['cy'] + 1.0\n\n        return adjusted_params\n\n    def model_sensor_noise(self, base_noise_params):\n        \"\"\"Model real sensor noise based on simulation\"\"\"\n        # Real sensors typically have more noise\n        real_noise_params = {\n            'gaussian_std': base_noise_params['gaussian_std'] * 1.2,\n            'dropout_rate': base_noise_params.get('dropout_rate', 0) + 0.05,\n            'bias_drift': 0.01  # Real sensors have bias drift\n        }\n\n        return real_noise_params\n\n    def account_for_latency(self, sim_processing_time):\n        \"\"\"Account for processing latency differences\"\"\"\n        # Real systems have additional communication and processing delays\n        real_processing_time = sim_processing_time + 0.02  # Add 20ms delay\n        return real_processing_time\n\n    def adjust_for_gpu_differences(self, sim_gpu_load):\n        \"\"\"Adjust for different GPU performance\"\"\"\n        # Account for differences in GPU compute capability\n        gpu_factor = self.measure_real_gpu_performance()\n        adjusted_load = sim_gpu_load * gpu_factor\n        return adjusted_load\n\n    def measure_real_gpu_performance(self):\n        \"\"\"Measure real GPU performance relative to simulation\"\"\"\n        # Benchmark GPU performance\n        import time\n        import numpy as np\n\n        # Simple benchmark: matrix multiplication\n        size = 1000\n        a = np.random.random((size, size)).astype(np.float32)\n        b = np.random.random((size, size)).astype(np.float32)\n\n        start_time = time.time()\n        _ = np.dot(a, b)\n        elapsed_time = time.time() - start_time\n\n        # Compare with expected performance\n        expected_time = 0.1  # Expected time on reference GPU\n        performance_factor = expected_time / elapsed_time\n\n        return performance_factor\n"})}),"\n",(0,i.jsx)(n.h3,{id:"2-isaac-ros-control-transfer",children:"2. Isaac ROS Control Transfer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class IsaacROSControlTransfer:\n    def __init__(self):\n        self.control_parameters = {\n            'control_frequency': 50,  # Hz\n            'feedback_delay': 0.02,   # 20ms delay\n            'actuator_dynamics': {\n                'time_constant': 0.05,\n                'saturation_limits': [-1.0, 1.0],\n                'deadband': 0.01\n            }\n        }\n\n    def tune_control_parameters(self, robot_type):\n        \"\"\"Tune control parameters for specific robot type\"\"\"\n        if robot_type == 'husky':\n            return {\n                'linear_vel_limit': 1.0,\n                'angular_vel_limit': 0.5,\n                'acceleration_limit': 0.5,\n                'control_frequency': 40\n            }\n        elif robot_type == 'turtlebot3':\n            return {\n                'linear_vel_limit': 0.22,\n                'angular_vel_limit': 2.84,\n                'acceleration_limit': 0.5,\n                'control_frequency': 30\n            }\n        elif robot_type == 'fetch':\n            return {\n                'linear_vel_limit': 0.5,\n                'angular_vel_limit': 1.0,\n                'acceleration_limit': 0.25,\n                'control_frequency': 100\n            }\n        else:\n            # Default parameters\n            return self.control_parameters\n\n    def implement_safety_fallbacks(self):\n        \"\"\"Implement safety fallbacks for real robot deployment\"\"\"\n        # Emergency stop publisher\n        self.emergency_stop_pub = self.create_publisher(\n            Bool, '/emergency_stop', 10\n        )\n\n        # Safety monitoring\n        self.safety_monitor = SafetyMonitor()\n        self.safety_monitor.start_monitoring()\n\n        # Fallback controller\n        self.fallback_controller = FallbackController()\n\n    def validate_control_transfer(self, sim_controller, real_controller):\n        \"\"\"Validate control transfer between sim and real\"\"\"\n        # Compare control responses\n        test_inputs = [0.1, 0.5, 1.0, -0.5, -1.0]\n\n        sim_responses = []\n        real_responses = []\n\n        for input_val in test_inputs:\n            sim_resp = sim_controller.get_response(input_val)\n            real_resp = real_controller.get_response(input_val)\n\n            sim_responses.append(sim_resp)\n            real_responses.append(real_resp)\n\n        # Calculate similarity metrics\n        correlation = np.corrcoef(sim_responses, real_responses)[0, 1]\n        rmse = np.sqrt(np.mean((np.array(sim_responses) - np.array(real_responses))**2))\n\n        return {\n            'correlation': correlation,\n            'rmse': rmse,\n            'max_error': np.max(np.abs(np.array(sim_responses) - np.array(real_responses)))\n        }\n"})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices-for-successful-transfer",children:"Best Practices for Successful Transfer"}),"\n",(0,i.jsx)(n.h3,{id:"1-validation-strategy",children:"1. Validation Strategy"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class TransferValidationStrategy:\n    def __init__(self):\n        self.validation_phases = [\n            \'component_validation\',\n            \'integration_validation\',\n            \'full_system_validation\',\n            \'long_term_validation\'\n        ]\n\n    def validate_component_level(self, component):\n        """Validate individual components"""\n        tests = [\n            self.test_component_stability,\n            self.test_component_response,\n            self.test_component_limits,\n            self.test_component_noise_handling\n        ]\n\n        results = {}\n        for test in tests:\n            results[test.__name__] = test(component)\n\n        return results\n\n    def validate_integration_level(self, integrated_system):\n        """Validate component integration"""\n        # Test component interactions\n        interaction_tests = [\n            self.test_sensor_actuator_interaction,\n            self.test_control_perception_coupling,\n            self.test_timing_constraints\n        ]\n\n        results = {}\n        for test in interaction_tests:\n            results[test.__name__] = test(integrated_system)\n\n        return results\n\n    def validate_system_level(self, complete_system):\n        """Validate complete system"""\n        # End-to-end functionality tests\n        system_tests = [\n            self.test_complete_task_execution,\n            self.test_error_recovery,\n            self.test_long_term_stability\n        ]\n\n        results = {}\n        for test in system_tests:\n            results[test.__name__] = test(complete_system)\n\n        return results\n'})}),"\n",(0,i.jsx)(n.h3,{id:"2-gradual-deployment",children:"2. Gradual Deployment"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class GradualDeployment:\n    def __init__(self):\n        self.deployment_levels = [\n            \'teleoperation_assistance\',\n            \'supervised_autonomy\',\n            \'semi_autonomous\',\n            \'fully_autonomous\'\n        ]\n        self.current_level = 0\n\n    def advance_deployment_level(self, performance_metrics):\n        """Advance to next deployment level based on performance"""\n        if self.current_level >= len(self.deployment_levels) - 1:\n            return False  # Already at maximum level\n\n        # Check if current level performance is satisfactory\n        if (performance_metrics[\'success_rate\'] > 0.9 and\n            performance_metrics[\'safety_score\'] > 0.95):\n\n            self.current_level += 1\n            self.log_deployment_level_change()\n            return True\n        else:\n            return False\n\n    def log_deployment_level_change(self):\n        """Log deployment level change"""\n        current_mode = self.deployment_levels[self.current_level]\n        self.get_logger().info(f"Advanced to deployment level: {current_mode}")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting-transfer-issues",children:"Troubleshooting Transfer Issues"}),"\n",(0,i.jsx)(n.h3,{id:"1-common-transfer-problems",children:"1. Common Transfer Problems"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Problem"}),(0,i.jsx)(n.th,{children:"Symptoms"}),(0,i.jsx)(n.th,{children:"Solutions"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Dynamics Mismatch"})}),(0,i.jsx)(n.td,{children:"Robot moves differently than expected"}),(0,i.jsx)(n.td,{children:"System identification, friction modeling"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Sensor Noise"})}),(0,i.jsx)(n.td,{children:"Perception fails in real world"}),(0,i.jsx)(n.td,{children:"Domain randomization, noise modeling"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Timing Issues"})}),(0,i.jsx)(n.td,{children:"Control unstable or delayed"}),(0,i.jsx)(n.td,{children:"Latency modeling, real-time constraints"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Hardware Limitations"})}),(0,i.jsx)(n.td,{children:"Robot can't execute planned motions"}),(0,i.jsx)(n.td,{children:"Kinodynamic constraints, hardware-aware planning"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"2-debugging-transfer-issues",children:"2. Debugging Transfer Issues"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class TransferDebugger:\n    def __init__(self):\n        self.debug_modes = {\n            'visualize_differences': self.visualize_sim_real_differences,\n            'log_sensor_data': self.log_sensor_comparison,\n            'compare_trajectories': self.compare_motion_trajectories,\n            'analyze_failures': self.analyze_failure_modes\n        }\n\n    def diagnose_transfer_issue(self, sim_data, real_data):\n        \"\"\"Diagnose common transfer issues\"\"\"\n        issues = []\n\n        # Check for timing differences\n        if self.detect_timing_issues(sim_data, real_data):\n            issues.append({\n                'type': 'timing',\n                'severity': 'high',\n                'solution': 'Check communication delays and control frequency'\n            })\n\n        # Check for sensor differences\n        if self.detect_sensor_issues(sim_data, real_data):\n            issues.append({\n                'type': 'sensing',\n                'severity': 'high',\n                'solution': 'Review sensor calibration and noise models'\n            })\n\n        # Check for dynamics differences\n        if self.detect_dynamics_issues(sim_data, real_data):\n            issues.append({\n                'type': 'dynamics',\n                'severity': 'medium',\n                'solution': 'Perform system identification'\n            })\n\n        return issues\n\n    def detect_timing_issues(self, sim_data, real_data):\n        \"\"\"Detect timing-related issues\"\"\"\n        # Compare execution times, control frequencies, etc.\n        pass\n\n    def detect_sensor_issues(self, sim_data, real_data):\n        \"\"\"Detect sensor-related issues\"\"\"\n        # Compare sensor outputs, noise characteristics, etc.\n        pass\n\n    def detect_dynamics_issues(self, sim_data, real_data):\n        \"\"\"Detect dynamics-related issues\"\"\"\n        # Compare motion patterns, accelerations, etc.\n        pass\n"})}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"Sim-to-real transfer remains one of the most challenging aspects of robotics development, but with proper techniques and methodologies, it's possible to achieve successful deployment of simulation-trained capabilities on real robots. The key is to understand and account for the reality gap through domain randomization, system identification, and gradual validation. By implementing robust transfer learning techniques and thorough validation strategies, developers can bridge the gap between simulation and reality, enabling the deployment of complex robotic behaviors in the real world. The techniques covered in this guide provide a foundation for achieving successful sim-to-real transfer in Physical AI applications."})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>o});var s=a(6540);const i={},t=s.createContext(i);function r(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);